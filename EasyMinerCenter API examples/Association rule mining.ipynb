{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Association Rule Mining using EasyMiner API\n",
    "This example demonstrates the possibility of association rule mining using complex REST API of data mining system EasyMiner.\n",
    "<br /><br />\n",
    "To use this example, you must have a working instance of EasyMiner. For testing purposes, you can use our demo server.\n",
    "\n",
    "## Dataset IRIS\n",
    "This example code is based on daset IRIS from the [UCI Repository](https://archive.ics.uci.edu/ml/datasets/iris). The file used in this exmample is located in the folder with this notebook: [iris.csv](./iris.csv)\n",
    "<br /><br />\n",
    "The dataset contains columns *sepallength*, *petalwidth*, *sepalwidth*, *petallength* and *class*. For rule miming also as for classification model building, the column *class* should be used in consequent part of rules, other columns should be used in antecedent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup variables, import dependencies\n",
    "To run this example, you have to configure the following variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requested libraries\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "# Configure access variables\n",
    "API_URL = 'https://br-dev.lmcloud.vse.cz/easyminercenter/api'\n",
    "API_KEY = 'mfC87Pp75zn018098owhU089J461260m75AtGGkybwDEtiTqejE'\n",
    "\n",
    "# Setup details about the used file\n",
    "CSV_FILE = 'iris.csv'\n",
    "CSV_SEPARATOR = ','\n",
    "CSV_ENCODING = 'utf8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload CSV file to EasyMiner server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP request for uploading of the CSV file\n",
    "r = requests.post(API_URL + '/datasources?separator=' + urllib.parse.quote(CSV_SEPARATOR) + '&encoding=' + CSV_ENCODING + '&type=limited&apiKey=' + API_KEY, files = {(\"file\", open(CSV_FILE, 'rb'))}, headers = {\"Accept\": \"application/json\"})\n",
    "\n",
    "# Get datasource ID (identificates the dataset on EasyMiner server) from the server response\n",
    "datasource_id = r.json()[\"id\"]\n",
    "\n",
    "# For debug purposes, print datasource_id - if the datasource was created successfully, the datasource_id should be greater than )  \n",
    "print('Created datasource ID: '+str(datasource_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Miner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define name for the miner {optional value for your better orientation in list of miners]\n",
    "miner_name = 'TEST MINER'\n",
    "\n",
    "# JSON configuration of the API request (will be sent as body of the HTTP request)\n",
    "json_data = json.dumps({\"name\": miner_name, \"type\": \"cloud\", \"datasourceId\": datasource_id})\n",
    "\n",
    "# Send request for miner creation\n",
    "r = requests.post(API_URL + \"/miners?apiKey=\" + API_KEY, headers = {'Content-Type': 'application/json', \"Accept\": \"application/json\"}, data = json_data.encode())\n",
    "\n",
    "# Get ID of the created miner (identificates the miner on EasyMiner server)\n",
    "miner_id = r.json()[\"id\"]\n",
    "\n",
    "# For debug purposes, print datasource_id - if the datasource was created successfully, the datasource_id should be greater than )  \n",
    "print('Created miner ID: '+str(miner_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocess data \n",
    "It is not possible to use the uploaded data fields from the uploaded datasource directly for definition of the data mining task. You have to generate attribute from each attribute you want to use.\n",
    "<br /><br />\n",
    "The simplest preprocessing method is to use the values of the data field \"as they are\" using the preprocessing method \"each value - one bin\".\n",
    "<br /><br />\n",
    "The uploaded data fields are identified using their names. Remember, the names has not be exactly the same as in the uploaded file (in case of duplicities etc.). You should get the list of data fields (columns) in the datasource:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request from the EasyMiner list of columns (data fields) available in the existing datasource\n",
    "r = requests.get(API_URL + '/datasources/' + str(datasource_id) + '?apiKey=' + API_KEY, headers = {'Content-Type': 'application/json', \"Accept\": \"application/json\"})\n",
    "\n",
    "# The response contains properties of the datasource also as the list of columns. Get only the columns... \n",
    "datasource_columns = r.json()['column']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of preprocessing requests\n",
    "# In case you want to preprocess all the columns from the data field using the method \"each value - one bin\", you can simple use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datasource_columns:\n",
    "    # You can work with the column name or the column ID. Both these values are parsed from the previous JSON response.\n",
    "    column_name = col['name']\n",
    "    \n",
    "    # You have to select \n",
    "    attribute_name = column_name\n",
    "    \n",
    "    # Construct the definition of preprocessing request; \n",
    "    # for identification of the column from datasource, you can use its ID (set it to property \"column\"), or its name (set it to property \"columnName\").. \n",
    "    json_data = json.dumps({\"miner\": miner_id, \"name\": attribute_name, \"columnName\": column_name, \"specialPreprocessing\": \"eachOne\"})\n",
    "    \n",
    "    # Send the request and wait for the response;\n",
    "    # dependently on the size of the used datasource, it can take a bit longer time...\n",
    "    r = requests.post(API_URL + \"/attributes?apiKey=\" + API_KEY, headers = {'Content-Type': 'application/json', \"Accept\": \"application/json\"}, data = json_data.encode())\n",
    "    if r.status_code != 201:\n",
    "        break  # error occurred - the preprocessing of the selected attribute failed \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
